# Spark-hadoop-yarn-multinode-docker-cluster
A docker setup to run pyspark scripts on hadoop file system and yarn resource manager in cluster mode.
